3.1:ubuntu系统配置，软件安装。AudioTrack大致过程
Ubuntu:
1.sudo apt-get install *** 失败。
解决方案：sudo apt-get update 

2.Could not get lock 	/var/lib/dpkg/lock......
Solve: ps afx|grep apt
 sudo Kill -9 1234

 sudo rm /var/lib/dpkg/lock
sudo dpkg --configure -a
sudo apt-get update


AudioTrack:
audiotrack(只用于播放PCM数据流）
应用场合：时延要求高。

代码：
AudioTrack test_track = new AudioTrack(STREAM_TYPE,SR,CONF,FORMAT,minBuffersize,MODE);
track.write(data, 0, data.length);
track.play();
track.release();


详解：步骤：1.创建一个AudioTrack的实例2.调用track.write写入回放数据3.调用 play() 开始播放4.播放完成后调用 release() 释放 AudioTrack 实例.

STREAM_TYPE:STREAM_VOICE_CALL,STREAM_SYSTEM,STREAM_RING,STREAM_MUSIC,STREAM_ALARM,STREAM_NOTIFICATION,STREAM_DTMF.

FORMAT:AudioFormat.ENCODING_PCM_16BIT,AudioFormat.ENCODING_PCM_8BIT.

MODE：MODE_STATIC,MODE_STREAM.

minBufferSize通过AudioTrack.getMinBufferSize获取。（××）

3.2:AudioTrack具体构建setup过程

创建过程：
path:/java/android/media/AudioTrack.java：
1.构造AudioTrack函数
2.获取主线程looper（××）
3.获取参数类型
4.参数检查audioParamCheck
5.调用native_setup
path:/jni/android_media_AudioTrack.cpp：
1.用 JNINativeMethod gMethods[] 将 native_setup替换成 android_media_AudioTrack_setup.

（native层）AudioTrack.cpp：
1.创建native层的AudioTrack对象.
path:/jni/android_media_AudioTrack.cpp：
从AudioSystem中获取信息：AudioSystem::getOutput***();
*** : SamplingRate / FrameCount / Latency / ForPttr / Effect /SampllingRate

path:/libaudioclient/AudioTrack.cpp：
1.AudioTrack::set()设置setup所需各项参数;
2.create the IAudioTrack.

 
3.3:AudioFlinger,AudioSystem，createtrack???

建立完createTrack_l之后，下一步是？	
总：在AudioTrack.cpp里面调用AudioFlinger::createTrack()里的createTrack_l()来完成音频策略服务最终返回AudioTrack.

分： 时序图：4。Audiosystem::getoutputforattr();,然后在audiopolicyservice::getoutputforattr(),然后再audiopolicymanager::getoutputforattr().这一步叫做通过binder机制 （××）获取音频策略服务。
下一步是在audiotrack.cpp中调用audioflinger::createtrack();所以就到了audioflinger.cpp下，
为什么要调用呢？：：理由是用来创建share buffer。 利用共享内存提高效率。APP中的 AudioTrack与PlaybackThread可以访问同一块内存.
Q:共享内存是谁创建的呢？
A：根据MODE判断，若是MODE_STATIC，则由APP中AudioTrack创建；若是MODE_STREAM，则是PlaybackThread创建。
那么audioflinger::createtrack()方法如何工作呢？
先看定义：

//获取回放线程PlaybackThread 
PlaybackThread *thread = checkPlaybackThread_l(output);
//调用刚才获取到的playbackthread中的createtrack_l()
track = thread->createTrack_l(...);
//创建track的binder对象trackhandle,然后返回给audiotrack
trackHandle = new TrackHandle(track);
return trackHandle;

到此为止，audiotrack_setup结束。


3.4:createTrack具体步骤

1.//获取回放线程PlaybackThread.
path:/frameworks/av/services/audioflinger/AudioFlinger.cpp:

PlaybackThread *thread = checkPlaybackThread_l(output);

2.//调用AudioFlinger::PlaybackThread::createTrack_l()，使用new Track来实现share buffer
path:: /frameworks/av/services/audioflinger/AudioFlinger.cpp:

track = thread->createTrack_l(...);
path:/frameworks/av/services/audioflinger/Threads.cpp：

track = new Track(...);  //创建playbackthread::track。
...
mTracks.add(track);    //将track加入到playbackthread的track列表mtracks中。

3.在AudioFlinger中创建出来的Track需要通过binder对象才能被传回AudioTrack,因此先在AudioFlinger中创建BnBinder对象:TrackHandle.
path: /frameworks/av/services/audioflinger/AudioFlinger.cpp:

sp<TrackHandle> trackHandle;
...
trackHandle = new TrackHandle(track);
...
return trackHandle;

4.AudioFlinger::createTrack()返回TrackHandle,其中包含set信息。再返回到AudioTrack.
path: /frameworks/av/media/libaudioclient/AudioTrack.cpp:

sp<IAudioTrack> track = audioFlinger->createTrack(...);
mAudioTrack = track;

下一步是？
准备完毕，开始start.
audiotrack_start()函数.


3.7:从头整理一遍audiotrack_setup;start,stop...


3.4.1 new track继承了trackbase..这一部分没有深入跟踪（×××）其他的按照audiotrack_1的图来，基本没问题。

start步骤：

在start()之前，audiotrack::createtrack_l()最后执行maudiotrack = track ; 
start只是调用track->start()来实现音频输出。
path:libaudioclient/AudioTrack.cpp
status = mAudioTrack->start(&status);

path:audioflinger/Tracks.cpp
AudioFlinger::PlaybackThread::Track::start(){
...
PlaybackThread *playbackThread = (PlaybackThread *)thread.get();
...
status = playbackThread->addTrack_l(this);
...
}



AudioFlinger::PlaybackThread::addTrack_l（）：
在addTrack_l方法内，主要步骤有三个：
//如果该track（share buffer）是新增track，则需要调用startOutput进行初始化
status = AudioSystem::startOutput(track->portId()) ;
//把该track加入mActiveTracks
mActiveTracks.add(track);
//发送广播，通知MixerThread开始工作
broadcast_l();


3.8:学习audiotrack::write( ).
学习AudioFlinger：：openOutput,
AudioPolicyManager：：getOutputForDevices

1.audiotrack::write( )
1.path:AudioTrack.java::write():参数和状态验证，调用native_write_byte。
2.JNI层：native_write_byte()--------->>>android_media_AudioTrack_writeArray()
2.1AudioTrack::writeArray():
	2.1.1//取出之前创建的AudioTrack。
	sp<AudioTrack> lpTrack = getAudioTrack(env, thiz);
	2.1.2//参数检查..
	2.1.3//将取出的audiotrack 写入
	jint samplesWritten = writeToTrack(lpTrack，......)
		2.1.3.1//将数据给本地的AudioTrack的对象。如果共享buffer为0，stream		模式，则写入数据.
		 if (track->sharedBuffer() == 0)
		{
		 written = track->write()
		....
		}
		2.1.3.2//参数检查...
		2.1.3.3//obtainBuffer()获取可用Buffer。
		status_t err = obtainBuffer()
			2.1.3.3.1 //获得一个代理，进入proxy的obtainBuffer(),这里应该进入到AudioTrackClientProxy,AudioTrackClientProxy继承ClinetProxy,所以用
path:libaudioclient/AudioTrackShared.cpp下的 ClientProxy::obtainBuffer（）。
				code:
				sp<AudioTrackClientProxy> proxy;
				proxy = mProxy;
				status = proxy->obtainBuffer(...);
				...
				//获取客户端对象
				audio_track_cblk_t* cblk = mCblk;
				...
				//得到一个有数据的obtainbuffer。获得buffer的帧数和size。
				return status;
		2.1.3.4//memcpy()写入,进行memcpy()后，获得copy后的audiobuffer。
				memcpy(audioBuffer.i8, buffer, toWrite);
			2.1.3.5//释放buffer
				releaseBuffer(&audioBuffer);
				2.1.3.5.1 
				 mProxy->releaseBuffer(&buffer);

				

重点函数分析：
1.AudioFlinger::openOutput()


3.9:AudioFlinger::openOutput()

1.openoutput_l()
1.1findsuitablehwdev_l()		//加载module，并初始化其操作函数。
1.1.1 loadHwModule_l()
1.1.1.1 strncmp()		//字符遍历，检查是否已经加载过mAudioHwDevs
1.1.1.2 mDevicesFactoryHal->openDevice()
//根据名字获取AudioHwDev，并打开
1.1.1.2.1path:libaudiohal/impl/DevicesFactoryHalLocal.cpp
method:load_audio_interface():
hw_get_module_by_class。//获取module
audio_hw_device_open。 //打开设备，对该module的操作函数进行初始化.
audio_hw_device_close。
1.1.1.3 nextUniqueId()//创建AudioHwDev唯一对应的ID
1.1.1.4 mAudioHwDevs.add(handle, audioDevice);
//handle和AudioHwDevice是一对键值对，传入mAudioHwDevs列表里，通过audio_module_handle_t类型变量handle，可以获得硬件设备，把这个设备加入设备数组中进行维护.
1.1.2 path:libaudiohal/impl/DeviceHalLocal.cpp:
method:getSupportedDevices()


3.10:接上AudioFlinger::openOutput()

1.2 path:audioflinger/AudioHwDevice.cpp:
openOutputStream()				//打开音频输出流～
1.2.1 new AudioStreamOut()	//创建AudioStreamOut音频输出流
1.2.2 outputStream->open()
 		 path:audioflinger/AudioStreamOut.cpp:
AudioStreamOut::open()
1.2.2.1 hwDev()->openOutputStream()//打开音频输出流
1.2.3PlaybackThread *playbackThread = (PlaybackThread *)thread.get()
//获取音频输出线程
1.2.4mPrimaryHardwareDev = playbackThread->getOutput()->audioHwDev
//将传进来的module作为主音频接口
1.2.4.1 mPrimaryHardwareDev->hwDevice()->setMode(mMode)
1.3 mPlaybackThreads.add(*output, thread);



3.11AudioPolicyManager：：getOutputForDevices

1.openDirectOutput()
getProfileForOutput()
hwModule->getOutputProfiles()
new SwAudioOutoputDescriptor()
releaseMsdOutputPatches()
outputDesc->open()
outputDesc->close()
addOutput()
mpClientInterface->onAudioPortListUpdate()
path:AudioPolicyClientImpl.cpp
mAudioPolicyService->onAudioPortListUpdate()
2.getOutputsForDevices()
outputs.add(openOutputs.keyAt(i))
3.selectOutput().


3.15所学内容+AudioRecord.




3.16 1.完善AudioFlinger::openOutput()和AudioPolicymanager::getOutputForDevices().
2.熟悉AudioRecord.
AudioRecord:(和AudioTrack很类似，对比学习）
1.setup:
path:AudioRecord.java
code://初始化 AuidoTrack对象
public AudioRecord(){
...
int initResult = native_setup(...）;
..
}
1.1path:jni/android_media_AudioRecord.cpp
//将native_setup 替换成 android_media_AudioRecord_setup
1.1.1android_media_AudioRecord_setup：
keycode:
sp<AudioRecord> lpRecorder = 0;
lpRecorder = new AudioRecord(String16(opPackageNameStr.c_str()));
const status_t status = lpRecorder->set(..);
1.1.1.1 path:libaudioclient/AudioRecord.cpp
keycode:
 status = createRecord_l(0 /*epoch*/, mOpPackageName);

createRecord_l:
 record = audioFlinger->createRecord(input, output, &status);
//调用到AudioFlinger::createRecord()
createRecord():
lStatus = AudioSystem::getInputForAttr(...);
RecordThread *thread = checkRecordThread_l(output.inputId);
recordTrack = thread->createRecordTrack_l(...);


3.17 AudioRecord::start(),read();MediaSession.

在之前的 AudioTrack::set()中，有这样一句调用：AudioSystem::getOutputForAttr(),实际上这里用到了Binder转到IAudioPolicyService::getOutputForAttr(),在这里选择设备配置。并会创建一个playbackthread。这在之后的AudioFlinger::checkplaybackThread()中用到。

同理， AudioRecord::set()中，有这样一句调用：AudioSystem::getInputForAttr(),这里也用到了Binder转到IAudioPolicyService::getInputForAttr(),在这里选择设备配置。并创建一个RecordThread.这在之后的AudioFlinger::checkRecordThread()中会用到。

今天没有看audiorecord::start(),原因是在此函数中发现又有start()调用,没有找到对应的函数，搜索才发现此时应该到Tracks.cpp下面去找，这就和thread有关，所以将重点转到了recordthread.



3.21 Audiorecord::start(),read(),mediasession.

start()没看懂调用流程

read():
1.path:audiorecord.java:
code:public int read() --> native_read_in_byte_array 
2.path:jni/android_media_AudioRecord.cpp:
code: 2.1 android_media_AudioRecord_readInArray() 
2.1.1sp<AudioRecord> lpRecorder = getAudioRecord();
2.1.2ssize_t readSize = lpRecorder->read();
3. path:libaudioclient/AudioRecord.cpp:
code:3.1 status_t err = obtainBuffer(...) --> AudioRecord::obtainBuffer()
3.1.1  sp<AudioRecordClientProxy> proxy
status = proxy->obtainBuffer()
3.1.1.1path:AudioTrackShared.cpp
code: ClientProxy::obtainBuffer()
return status
4. memcpy()
5.releaseBuffer(&audioBuffer)  --> AudioRecord::releaseBuffer()
5.1 mProxy->releaseBuffer()
5.1.1 path:AudioTrackShared.cpp
code:ClientProxy::releaseBuffer()

mediasession:
mediasession主要可以分为四大类，MediaBrowser,MediaController,MediaBrowserService,MediaSession.
其中MediaBrowser,MediaController可以归属到客户端，MediaBrowserService,MediaSession归属到服务端，



3.22 Audio通路切换

1.在AudioSystem.java中，规定了音频输出通道device，例如 FORCE_SPEAKER，FORCE_HEADPHONES ，FORCE_WIRED_ACCESSORY等。
2.此外，还需要制定音频播放模式MDOE，比如MODE_NORMAL，MODE_RINGTONE，MODE_IN_CALL，MODE_IN_COMMUNICATION，
3.音频流类型audio stream names.比如STREAM_DEFAULT，STREAM_VOICE_CALL，STREAM_SYSTEM,STREAM_BLUETOOTH_SCO等等，

这三者之间的关系是什么？
device和mode是一起规定的，而stream和mode有联系。

AudioSystem::getOutputForAttr()  //深层会涉及到设备通路切换...
问题1.没找到从aps到apm的getoutputforattr()
问题2.分析audiosystem中的getoutputfotattr()

1.audiosystem::getOutputForAttr()  --> audiopolicyservice(Bn)::getOutputForAttr()  --> audiopolicymanager::getOutputForAttr()

现在看到AudioPolicyManager::getOutputForAttr(）：

1. status_t status = getOutputForAttrInt（...)
1.1 status_t status = getAudioAttributes(...) 
1.1.1 *dstAttr = mEngine->getAttributesForStreamType(srcStream); 
1.2 *stream = mEngine->getStreamTypeForAttributes(*resultAttr); 
1.3 outputDevices = mEngine->getOutputDevicesForAttributes(...) 
1.3.1 getProductStrategyForAttributes() 
1.3.2 getDevicesForProductStrategy() 
1.4 getOutputForDevices() 
1.4.1 openDirectOutput() 
1.4.1.1 getProfileForOutput() 
1.4.1.2 addOutput() 
1.4.2 getOutputsForDevices() 
1.4.3 selectOutput()



3.23. 细化getOutputForAttr()流程分析。
这里所说的memorytype，其实就是指MODE_STREAM和 MODE_STATIC.

Getoutputforattr()具体流程：
1. status_t status = getOutputForAttrInt（...)
1.1 status_t status = getAudioAttributes(...) 
1.1.1 *dstAttr = mEngine->getAttributesForStreamType(srcStream); 
1.2 *stream = mEngine->getStreamTypeForAttributes(*resultAttr); 
1.3 outputDevices = mEngine->getOutputDevicesForAttributes(...) 
1.3.1 getProductStrategyForAttributes() 
1.3.2 getDevicesForProductStrategy() 
1.4 getOutputForDevices() 
1.4.1 openDirectOutput() 
1.4.1.1 getProfileForOutput() 
1.4.1.2 addOutput() 
1.4.2 getOutputsForDevices() 
1.4.3 selectOutput()

怎么抓取log?
1.安装好adb工具及环境配置。
2.以管理员身份运行cmd,在cmd中先输入adb的安装盘，例如D:(默认为C：）
3.进入到adb的安装目录（cd D:\adb\platform-tools)
4.手机打开usb调试，选择文件传输模式。cmd输入adb devices可以查看当前设备
5.cmd输入adb shell logcat -> D:\adb\test.txt（指定目录D:\adb，文件名test.txt）
6.操作...
7.Ctrl+c取消抓取。

Q1：没找到从aps到apm的getoutputforattr()
A1：audiosystem.cpp中的getouputforatttr()方法调用到IAudioPolicyService::getOutputForAttr(),但实际上AudioPolicyService的Bn端实现是在AudioPolicyInterfaceimpl.cpp中。audiopolicyservice的client代码是在AudioPolicyClientImpl.cpp中；


Q2：Dumpsys是啥？
A2：



3.24 log analyse+getoutputforattr()
log通识：
1.若要用adb在指定文件夹输出log，windows下和linux下的命令基本一致，只是文件路径有 \ 和 /  的区别（不一定先要转到adb安装目录下~）：
Windows: adb logcat -v time ->D:\adb\test.log
Linux： adb logcat -v time ->Desktop/test.log
2.log的后缀名为.log 或 .txt不影响输出。

手机端操作：在主界面打开网易云音乐，将音量调至最低，播放 My Dilemma 1s,然后将音量调大一格，持续5s，然后暂停，持续5s，然后继续播放5s,然后直接杀掉程序。

宏观log：
1.//从主页面打开网易云音乐
11:14:18.797 I/ActivityManager( 1824): Start proc 21170:com.netease.cloudmusic/u0a294 for pre-top-activity {com.netease.cloudmusic/com.netease.cloudmusic.activity.LoadingActivity} caller=com.miui.home
...
...
2.//从最近任务中kill进程
11:14:40.912 I/ProcessManager( 1824): SwipeUpClean: force-stop com.netease.cloudmusic Adj=0 State=4
11:14:40.913 I/ActivityManager( 1824): Force stopping com.netease.cloudmusic appid=10294 user=0: SwipeUpClean
11:14:40.915 I/ActivityManager( 1824): Killing 21293:com.netease.cloudmusic:browser/u0a294 (adj 0): stop com.netease.cloudmusic due to SwipeUpClean

程序调用log：
1.// audiotrack::set()
11:14:21.754 D/AudioTrack(21265): set(): streamType -1, sampleRate 48000, format 0x1, channelMask 0x3, frameCount 3844, flags #0, notificationFrames 0, sessionId 0, transferType 3, uid -1, pid -1

2.//audioflinger::createtrack()
11:14:21.759 I/AudioFlinger(  995): create audiotrack for com.netease.cloudmusic  uid 10294

3.//AudioFlinger::PlaybackThread::createTrack_l()
11:14:21.759 D/AudioFlinger(  995): Client defaulted notificationFrames to 1922 for frameCount 3844
...
...



3.25 log analyse+getoutputforattr()

对log进行调用流程分析时，重点关注D级别的log能够更加快速地定位。
续3.24
宏观log：
1.//从主页面打开网易云音乐
11:14:18.797 I/ActivityManager( 1824): Start proc 21170:com.netease.cloudmusic/u0a294 for pre-top-activity {com.netease.cloudmusic/com.netease.cloudmusic.activity.LoadingActivity} caller=com.miui.home
...
...

4.//从最近任务中kill进程
11:14:40.912 I/ProcessManager( 1824): SwipeUpClean: force-stop com.netease.cloudmusic Adj=0 State=4
11:14:40.913 I/ActivityManager( 1824): Force stopping com.netease.cloudmusic appid=10294 user=0: SwipeUpClean
11:14:40.915 I/ActivityManager( 1824): Killing 21293:com.netease.cloudmusic:browser/u0a294 (adj 0): stop com.netease.cloudmusic due to SwipeUpClean


程序调用log：
// audiotrack::set()
11:14:21.754 D/AudioTrack(21265): set(): streamType -1, sampleRate 48000, format 0x1, channelMask 0x3, frameCount 3844, flags #0, notificationFrames 0, sessionId 0, transferType 3, uid -1, pid -1

//AudioPolicyManager::getOutputForAttr()
11:14:21.758 D/APM_AudioPolicyManager(  995): getOutputForAttr() returns output 29 requestedPortId 0 selectedDeviceId 3 for port ID 383

//AudioFlinger::PlaybackThread::createTrack_l()
11:14:21.759 D/AudioFlinger(  995): Client defaulted notificationFrames to 1922 for frameCount 3844

//TrackHandle
11:14:21.759 D/AF::TrackHandle(  995): OpPlayAudio: track:379 usage:1 not muted

//audiotrack::stop()
11:14:21.763 D/AudioTrack(21265): stop(383): prior state:STATE_STOPPED

3.28 规划近期需要学习的内容。

需要学习的内容按照优先级排序：Audio音频系统整体框架学习 -->宝哥和梓轩哥的PPT：音频策略，音量调用，bug实例 -->整理自己的框架和流程  --> 耳机插拔流程 --> mediasession -->音频焦点，蓝牙切换 -->dump节点，进度条卡断问题，播放杂音，录音噪音的问题.

1.Audio音频系统整体框架学习
Application framework(java) --> JNI (java native interface) --> native framework(cpp)
--> Binder (IPC:internal program communication) (ps:IAudiotrack,Iaudiorecord...) --> services(ps:audiopolicyservices,audioflingerservices) --> HAL
音频框架Application framework可以分为 multimedia 和audio,multimedia负责音频的编解码，解码后成PCM数据流，给audiotrack输出；Audiorecord的录音数据给multimedia来编码。

Audiotrack java API      Audiotrack native API
TRANSFER_MODE:
MODE_STREAM          TRANSFER_SYNC
MODE_STATIC			  TRANSFER_SHARED
STREAM_MODE:
AUDIO_STREAM_VOICE_CALL...

1.1各个线程之间的关系：


其中，playbackthread 和 输出流设备是一一对应的。



Primary_out设备是在系统启动的时候就已经打开（low_latency和deep_buffer设备也是）并创建好了mixerthread,只不过真正的硬件设备要等到playbackthread将音频数据写入的时候才会打开。

1.2AudioFlinger音频流控制
Playbackthread中有两个成员mTracks 和 mActiveTracks,在playbackthread中创建的所有track都会加入到mtracks中，而mActiveTracks中保存的只有那些status设置为active的track.
音频流控制主要就是start(),stop(),pause().状态分别为active,stopped,pausing.然后broadcast_l()通知playbackthread调用PlaybackThread::threadLoop() 中的preparetracks_l()重新准备状态。



1.3.
IAudioTrack：IAudioTrack 是链结 AudioTrack 与 AudioFlinger 的桥梁；它在 AudioTrack 端的对象是 BpAudioTrack，在 AudioFlinger 端的对象是 BnAudioTrack，从图中不难看出，AudioFlinger::TrackHandle 继承自 BnAudioTrack，而 AudioFlinger::TrackHandle 恰恰是AudioFlinger::PlaybackThread::Track 的代理对象，所以 AudioTrack 得到 IAudioTrack 实例后，就可以调用 IAudioTrack 的接口与 AudioFlinger::PlaybackThread::Track 交互.




Q1:PCM?
A1:脉冲编码调制：即模拟信号输入后听过采样量化编码的方式输出的数据流。
Q2:大小端是什么？
A2:大端存储：低位地址存放高位数据：例如0x12345678，大端存储为：
低地址  高地址
12 34   56 78
小端存储即低位地址存放低位数据，即
低地址 高地址
78 56  34 12 

